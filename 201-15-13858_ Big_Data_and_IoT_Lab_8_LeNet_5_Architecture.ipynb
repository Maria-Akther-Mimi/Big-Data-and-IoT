{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJW3CTLpIgsX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, average_precision_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary library to run code "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuBFm5DPIgwR"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   # CPU as Default, GPU= cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU in device available or not will be checked here. GPU is needed for heavy programming."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EBDpdKAIg33"
      },
      "outputs": [],
      "source": [
        "#Hyper parameter                     # Related to accuracy\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyper parameter includes batch_size, num_classes, learning_rate, num_epochs which is related to accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPwdFB1Lg5Ui"
      },
      "source": [
        "**Load the MNIST Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LH41LQKMggXi"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.Resize((32,32)),transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# resize data into 32*32 dimension ,preserved it into transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LylXr1PFgZKb"
      },
      "outputs": [],
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root = './data',\n",
        "                                           train = True,\n",
        "                                           transform = transform,\n",
        "                                           download = True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data is saven into ./data folder in our PC. For train dataset train will be \"True\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1ZPJrSpgpVr"
      },
      "outputs": [],
      "source": [
        "test_dataset = torchvision.datasets.MNIST(root = './data',\n",
        "                                          train = False,\n",
        "                                          transform = transform,\n",
        "                                          download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data is saven into ./data folder in our PC. For test dataset train will be \"False\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyI0ew58gz0C"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,                   # devide dataset according to batch size\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Mx27D_yiOwS",
        "outputId": "81606a72-6d61-4942-a57a-ed7001e5614c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "for X, y in train_loader:                                     # chech the train data dimension\n",
        "  print(X.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYXZoAknfrbD"
      },
      "source": [
        "**LeNet-5 Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUNnyl1PXflL"
      },
      "outputs": [],
      "source": [
        "                                                                           #convolution layer - Feature Extract , FC Layer - perform regression/classification\n",
        "                                                                           # For multiclass we use Softmax Activation function\n",
        "\n",
        "class LeNet(nn.Module):                                                 \n",
        "    def __init__(self):                                                  \n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv_layers= nn.Sequential(\n",
        "            nn.Conv2d(1,6,5), #[1, 6, 28, 28] #Gray image                 \n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(2,2), #[1, 6, 14, 14]\n",
        "            nn.Conv2d(6,16,5), #[1, 16, 10, 10]\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(2,2), #[1, 16, 5, 5]\n",
        "        )\n",
        "        self.fc_layers= nn.Sequential(\n",
        "            nn.Linear(16*5*5, 120), #120 neurons\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120,84), #84 neurons\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84,num_classes), #10 neurons\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x= self.conv_layers(x)\n",
        "        x= x.reshape(x.shape[0], -1)\n",
        "        x= self.fc_layers(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Firstly here used convolution layer for extract data. Then  Fully connected layer used to Classification task which needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSXWctyWaIqb",
        "outputId": "f0d36a7f-113c-4f8e-c8a1-596e312e5770"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LeNet(\n",
              "  (conv_layers): Sequential(\n",
              "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  )\n",
              "  (fc_layers): Sequential(\n",
              "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LeNet()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8Cc9ucjj6Ib"
      },
      "source": [
        "**Loss and optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mk8FlhAmgUEz"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)                        # Adam optimizer is used to update the model's parameters "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8FyWqHGjtB0"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqKCw5pvdy8y",
        "outputId": "89831dad-ee2a-4363-c78d-3fc13550ae15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [400/938], Loss: 0.2153\n",
            "Epoch [1/10], Step [800/938], Loss: 0.1203\n",
            "Epoch [2/10], Step [400/938], Loss: 0.3141\n",
            "Epoch [2/10], Step [800/938], Loss: 0.0695\n",
            "Epoch [3/10], Step [400/938], Loss: 0.1782\n",
            "Epoch [3/10], Step [800/938], Loss: 0.0137\n",
            "Epoch [4/10], Step [400/938], Loss: 0.0914\n",
            "Epoch [4/10], Step [800/938], Loss: 0.0073\n",
            "Epoch [5/10], Step [400/938], Loss: 0.0450\n",
            "Epoch [5/10], Step [800/938], Loss: 0.0124\n",
            "Epoch [6/10], Step [400/938], Loss: 0.0145\n",
            "Epoch [6/10], Step [800/938], Loss: 0.0136\n",
            "Epoch [7/10], Step [400/938], Loss: 0.0328\n",
            "Epoch [7/10], Step [800/938], Loss: 0.0157\n",
            "Epoch [8/10], Step [400/938], Loss: 0.1374\n",
            "Epoch [8/10], Step [800/938], Loss: 0.0043\n",
            "Epoch [9/10], Step [400/938], Loss: 0.0063\n",
            "Epoch [9/10], Step [800/938], Loss: 0.0223\n",
            "Epoch [10/10], Step [400/938], Loss: 0.0004\n",
            "Epoch [10/10], Step [800/938], Loss: 0.0016\n"
          ]
        }
      ],
      "source": [
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 400 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train the model over multiple epochs, iterating through the training data in batches.\n",
        "# In each iteration, calculate the loss, perform backpropagation, and update the model's weights using the optimizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBzd0IgXkAjL"
      },
      "source": [
        "**Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZqp4Em6f706",
        "outputId": "999a33c5-6c58-440b-dc52-8fe131237e14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 98.73 %\n",
            "Top-1 Error: 1.269999999999996 %\n"
          ]
        }
      ],
      "source": [
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "        predicted_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy= 100 * correct / total\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(accuracy))\n",
        "    top1_error = 100 - accuracy\n",
        "    print('Top-1 Error: {} %'.format(top1_error))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# After training, evaluate the model's accuracy on the test dataset.\n",
        "# calculated the top-1 error as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umoAB9--XIS1"
      },
      "source": [
        "**Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "_OgXlkJ3WPXM",
        "outputId": "40ed20bd-b127-4ff8-96a5-0bfcfcb01d24"
      },
      "outputs": [],
      "source": [
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "confusion = confusion_matrix(true_labels, predicted_labels)\n",
        "plt.figure(figsize=(num_classes, num_classes))\n",
        "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues', square=True, xticklabels=True, yticklabels=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a confusion matrix to visualize the model's performance in classifying each digit.\n",
        "# seaborn is used to create a heatmap for the confusion matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBmpQU6MXPQ0"
      },
      "source": [
        "**Classification report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7roFH5B1jFBC",
        "outputId": "ff4fc27f-51dc-4055-b95d-a3ac217d07a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       980\n",
            "           1       0.99      1.00      0.99      1135\n",
            "           2       0.99      0.98      0.98      1032\n",
            "           3       0.97      1.00      0.98      1010\n",
            "           4       0.99      0.99      0.99       982\n",
            "           5       1.00      0.97      0.98       892\n",
            "           6       0.99      0.99      0.99       958\n",
            "           7       1.00      0.98      0.99      1028\n",
            "           8       0.98      0.99      0.98       974\n",
            "           9       0.97      0.99      0.98      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "report = classification_report(true_labels, predicted_labels)\n",
        "print('\\n'+ report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# generate a classification report, including metrics like precision, recall, and F1-score, for each class (0-9)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-n8oZSbKYTOs",
        "outputId": "c5ffe0a7-5f57-4340-cce5-9c3b213613cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 0:\n",
            "Precision: 0.99\n",
            "Recall: 0.99\n",
            "F1-score: 0.99\n",
            "\n",
            "Class 1:\n",
            "Precision: 0.99\n",
            "Recall: 1.00\n",
            "F1-score: 0.99\n",
            "\n",
            "Class 2:\n",
            "Precision: 0.99\n",
            "Recall: 0.98\n",
            "F1-score: 0.98\n",
            "\n",
            "Class 3:\n",
            "Precision: 0.97\n",
            "Recall: 1.00\n",
            "F1-score: 0.98\n",
            "\n",
            "Class 4:\n",
            "Precision: 0.99\n",
            "Recall: 0.99\n",
            "F1-score: 0.99\n",
            "\n",
            "Class 5:\n",
            "Precision: 1.00\n",
            "Recall: 0.97\n",
            "F1-score: 0.98\n",
            "\n",
            "Class 6:\n",
            "Precision: 0.99\n",
            "Recall: 0.99\n",
            "F1-score: 0.99\n",
            "\n",
            "Class 7:\n",
            "Precision: 1.00\n",
            "Recall: 0.98\n",
            "F1-score: 0.99\n",
            "\n",
            "Class 8:\n",
            "Precision: 0.98\n",
            "Recall: 0.99\n",
            "F1-score: 0.98\n",
            "\n",
            "Class 9:\n",
            "Precision: 0.97\n",
            "Recall: 0.99\n",
            "F1-score: 0.98\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Calculate precision, recall, f1 score\n",
        "precision = precision_score(true_labels, predicted_labels, average=None)\n",
        "recall = recall_score(true_labels, predicted_labels, average=None)\n",
        "f1 = f1_score(true_labels, predicted_labels, average=None)\n",
        "\n",
        "\n",
        "for class_label in range(10):\n",
        "    print(f'Class {class_label}:')\n",
        "    print(f'Precision: {precision[class_label]:.2f}')\n",
        "    print(f'Recall: {recall[class_label]:.2f}')\n",
        "    print(f'F1-score: {f1[class_label]:.2f}')\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9OrRN3RfwLO"
      },
      "source": [
        "**Top1 error**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbPFRg-EW6OS",
        "outputId": "2ecf9268-6819-4afd-a183-fb123fa42465"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 98.73%\n",
            "Top-1 Error: 1.2700000000000102 %\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(true_labels, predicted_labels)* 100\n",
        "print(f'Accuracy: {accuracy:.2f}%')\n",
        "top1_error = 100 - accuracy\n",
        "print('Top-1 Error: {} %'.format(top1_error))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# calculate the top-1 error, which is the complement of accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-V1vg8g8Y246"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5mMIFKpIg-b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L21-z6TfIhBl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2Nx4PmEIhEP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
